<!--
 * @描述: 
 * @版本: V1_0
 * @作者: LiWanglin
 * @创建时间: 2020.02.28
 * @最后编辑人: LiWanglin
 * @最后编辑时间: 2020.02.28
 -->

# 2020_02_28

## 1. OpenVINO

- OpenVINO 是英特尔基于自身现有的硬件平台开发的一种可以加快高性能计算机视觉和深度学习视觉应用开发速度工具套件，支持各种英特尔平台的硬件加速器上进行深度学习，并且允许直接异构执行。
- OpenVINO 包括英特尔深度学习部署工具包，具有模型优化器和推理引擎，以及面向OpenCV和OpenVx的优化的传统计算机视觉库。
- OpenVINO工具包可通过基于英特尔架构的处理器（CPU）及核显（Integrated GPU）和深度学习加速器（FPGA、Movidius VPU）的深度学习加速芯片，增强视觉系统功能和性能。
- “在计算机视觉领域，业界有两类方法被广泛的使用。一类是深度学习的方法（主要做物体检测、目标识别），另外一类是传统的计算机视觉的方法（比如做光流的计算或者图像的增强），这两类方法实际上都有在被使用。在 OpenVINO 里面，我们对这两类方法都有很好的支持（针对后一种，英特尔在 OpenVINO 中集成了媒体软件开发套件 Media SDK，可帮助开发者调用英特尔 CPU 里面集成 GPU 资源来实现视频的编码、解码以及转码的操作）。OpenVINO 包含一个深度学习的部署工具套件，这个工具套件可以帮助开发者，把已经训练好的网络模型部署到目标平台之上进行推理操作，所以 OpenVINO 是帮助大家做推理的，而不是帮助大家做训练的。我们是帮助大家把这些训练的结果更好的、更快的能够部署到英特尔的目标平台上做推理操作。”英特尔中国区物联网事业部首席技术官兼首席工程师张宇博士解释到。
- 在推理引擎方面，OpenVINO的推理引擎实际上是一套C＋＋函数库以及C＋＋的类，这样一个推理引擎，实现的是对输入数据的处理，并得到最终的结果，推理引擎是经过简单、统一的API接口，来支持所有的英特尔架构，实现深度学习推理所需要的操作。这些操作包括对数据的读取、对输入输出数据格式的定义以及调用相应的硬件的插件，把这些中间的数据文件下载到你最终的执行平台之上，这是推理引擎要做的工作。
- 另外，OpenVINO这个工具套件访问实际上是分层的，不同的开发者可以根据自己的使用的要求以及开发的能力去选择不同的API接口进行调用OpenVINO。比如，对于一个新手，只是有一个好的想法，但没有相应的算法或者也不了解深度学习到底如何在硬件上进行实现的话，也可以通过OpenVINO里包含的很多应用的示例来进行学习实现。如果开发者是能力极强的“超级用户”，OpenVINO也可以提供直接调用硬件底层的接口实现对硬件直接的访问能力。
- 总结一下英特尔的OpenVINO？工具套件能带来的一些优势：首先是性能方面的提升，因为通过OpenVINO，大家可以方便的使用英特尔的各种硬件的加速资源，包括CPU、GPU、VPU、FPGA，这些资源能够帮助大家提升深度学习的算法在做推理的时候的性能，而且这些执行的过程中是支持异构处理和异步执行的，这样的话能够减少由于系统资源等待所占用的时间。另外，OpenVINO使用了经过优化以后的OpenCV和OpenVX，同时提供了很多应用示例，可以缩短开发时间。这些库都支持异构的执行，所以大家如果编程的话，编写一次，以后就可以通过异构的接口支撑跑在其他的硬件平台之上。
- 另外在深度学习方面，OpenVINO带有模型优化器、推理引擎以及超过20个预先训练的模型，大家可以利用给大家提供的这些工具，快速的实现自己基于深度学习的应用，而且OpenVINO？使用了OpenCV、OpeenVX的基础库，大家可以利用这些基础库去开发自己特定的算法，实现自己的定制和创新。
